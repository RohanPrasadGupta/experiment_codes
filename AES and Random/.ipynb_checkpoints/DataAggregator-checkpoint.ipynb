{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cddf12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec68b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interval of 5 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6478299b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the folder path containing Base64 encoded files for decryption: C:/Users/ROHAN/IotSimulation/Base64\n",
      "Enter the folder path to save merged data: C:/Users/ROHAN/IotSimulation/DecForAggreator\n",
      "Merged files saved in C:/Users/ROHAN/IotSimulation/DecForAggreator\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import base64\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def decrypt_ct_prime(ct_prime):\n",
    "    R1, encrypted_data, R2 = ct_prime.split('||')\n",
    "    json_data = encrypted_data[len(\"Encrypted(\"):-1]\n",
    "    decrypted_data = json.loads(json_data)\n",
    "    return decrypted_data\n",
    "\n",
    "def read_and_decrypt_files(folder_path_base64, folder_path_merged):\n",
    "    if not os.path.exists(folder_path_merged):\n",
    "        os.makedirs(folder_path_merged)\n",
    "\n",
    "    user_data = {}\n",
    "\n",
    "    for filename in os.listdir(folder_path_base64):\n",
    "        if filename.endswith('_base64.txt'):\n",
    "            file_path = os.path.join(folder_path_base64, filename)\n",
    "\n",
    "            with open(file_path, 'r') as file:\n",
    "                encoded_data = file.read()\n",
    "                padded_encoded_data = encoded_data + '==='\n",
    "                try:\n",
    "                    decoded_data = base64.b64decode(padded_encoded_data).decode('utf-8')\n",
    "                    decrypted_info = decrypt_ct_prime(decoded_data)\n",
    "\n",
    "                    user_id = decrypted_info['user_id']\n",
    "                    timestamp = datetime.strptime(decrypted_info['timestamp'], \"%Y-%m-%d %H_%M_%S\")\n",
    "                    if user_id not in user_data:\n",
    "                        user_data[user_id] = []\n",
    "                    user_data[user_id].append((timestamp, decrypted_info))\n",
    "                except Exception as e:\n",
    "                    print(f\"Error decoding file {filename}: {e}\")\n",
    "\n",
    "    for user_id, data in user_data.items():\n",
    "        data.sort(key=lambda x: x[0])  # Sort by timestamp\n",
    "        merged_data = []\n",
    "        current_batch = []\n",
    "        current_batch_time = None\n",
    "\n",
    "        for timestamp, info in data:\n",
    "            if current_batch_time is None or timestamp - current_batch_time <= timedelta(minutes=5):\n",
    "                current_batch.append(info)\n",
    "            else:\n",
    "                merged_data.append(current_batch)\n",
    "                current_batch = [info]\n",
    "            current_batch_time = timestamp\n",
    "\n",
    "        if current_batch:\n",
    "            merged_data.append(current_batch)\n",
    "\n",
    "        save_merged_data(merged_data, user_id, folder_path_merged)\n",
    "\n",
    "def save_merged_data(merged_data, user_id, folder_path):\n",
    "    for i, batch in enumerate(merged_data):\n",
    "        merged_filename = f\"user_{user_id}_merged_{i+1}.txt\"\n",
    "        merged_file_path = os.path.join(folder_path, merged_filename)\n",
    "        with open(merged_file_path, 'w') as merged_file:\n",
    "            json.dump(batch, merged_file, indent=4)\n",
    "\n",
    "def main():\n",
    "    folder_path_base64 = input(\"Enter the folder path containing Base64 encoded files for decryption: \")\n",
    "    folder_path_merged = input(\"Enter the folder path to save merged data: \")\n",
    "    read_and_decrypt_files(folder_path_base64, folder_path_merged)\n",
    "    print(f\"Merged files saved in {folder_path_merged}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8136cc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66595cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "C:/Users/ROHAN/IotSimulation/Base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011bf825",
   "metadata": {},
   "outputs": [],
   "source": [
    "C:/Users/ROHAN/IotSimulation/DecForAggreator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a69af96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e61894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interval of 20 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb5f0f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the folder path containing Base64 encoded files for decryption: C:/Users/ROHAN/IotSimulation/Base64\n",
      "Enter the folder path to save merged data: C:/Users/ROHAN/IotSimulation/DecForAggreator\n",
      "Merged files saved in C:/Users/ROHAN/IotSimulation/DecForAggreator\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import base64\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def decrypt_ct_prime(ct_prime):\n",
    "    R1, encrypted_data, R2 = ct_prime.split('||')\n",
    "    json_data = encrypted_data[len(\"Encrypted(\"):-1]\n",
    "    decrypted_data = json.loads(json_data)\n",
    "    return decrypted_data\n",
    "\n",
    "def read_and_decrypt_files(folder_path_base64, folder_path_merged):\n",
    "    if not os.path.exists(folder_path_merged):\n",
    "        os.makedirs(folder_path_merged)\n",
    "\n",
    "    user_data = {}\n",
    "\n",
    "    for filename in os.listdir(folder_path_base64):\n",
    "        if filename.endswith('_base64.txt'):\n",
    "            file_path = os.path.join(folder_path_base64, filename)\n",
    "\n",
    "            with open(file_path, 'r') as file:\n",
    "                encoded_data = file.read()\n",
    "                padded_encoded_data = encoded_data + '==='\n",
    "                try:\n",
    "                    decoded_data = base64.b64decode(padded_encoded_data).decode('utf-8')\n",
    "                    decrypted_info = decrypt_ct_prime(decoded_data)\n",
    "\n",
    "                    user_id = decrypted_info['user_id']\n",
    "                    timestamp = datetime.strptime(decrypted_info['timestamp'], \"%Y-%m-%d %H_%M_%S\")\n",
    "                    if user_id not in user_data:\n",
    "                        user_data[user_id] = []\n",
    "                    user_data[user_id].append((timestamp, decrypted_info))\n",
    "                except Exception as e:\n",
    "                    print(f\"Error decoding file {filename}: {e}\")\n",
    "\n",
    "    for user_id, data in user_data.items():\n",
    "        data.sort(key=lambda x: x[0])  # Sort by timestamp\n",
    "        merged_data = []\n",
    "        current_batch = []\n",
    "        current_batch_time = None\n",
    "\n",
    "        for timestamp, info in data:\n",
    "            if current_batch_time is None or timestamp - current_batch_time <= timedelta(minutes=20):\n",
    "                current_batch.append(info)\n",
    "            else:\n",
    "                merged_data.append(current_batch)\n",
    "                current_batch = [info]\n",
    "            current_batch_time = timestamp\n",
    "\n",
    "        if current_batch:\n",
    "            merged_data.append(current_batch)\n",
    "\n",
    "        save_merged_data(merged_data, user_id, folder_path_merged)\n",
    "\n",
    "def save_merged_data(merged_data, user_id, folder_path):\n",
    "    for i, batch in enumerate(merged_data):\n",
    "        merged_filename = f\"user_{user_id}_merged_{i+1}.txt\"\n",
    "        merged_file_path = os.path.join(folder_path, merged_filename)\n",
    "        with open(merged_file_path, 'w') as merged_file:\n",
    "            json.dump(batch, merged_file, indent=4)\n",
    "\n",
    "def main():\n",
    "    folder_path_base64 = input(\"Enter the folder path containing Base64 encoded files for decryption: \")\n",
    "    folder_path_merged = input(\"Enter the folder path to save merged data: \")\n",
    "    read_and_decrypt_files(folder_path_base64, folder_path_merged)\n",
    "    print(f\"Merged files saved in {folder_path_merged}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d127e76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61fb9f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c07a822",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe1884f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52b814df",
   "metadata": {},
   "source": [
    "# interval with 20 minutes and report for both decryption and aggretion in seperate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5a396b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a34885e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the folder path containing Base64 encoded files for decryption: C:/Users/ROHAN/IotSimulation/Base64\n",
      "Enter the folder path to save merged data: C:/Users/ROHAN/IotSimulation/DecForAggreator\n",
      "Enter the directory for the reports: C:/Users/ROHAN/IotSimulation\n",
      "Merged files saved in C:/Users/ROHAN/IotSimulation/DecForAggreator\n",
      "Reports saved in C:/Users/ROHAN/IotSimulation\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import base64\n",
    "import json\n",
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "from time import perf_counter\n",
    "\n",
    "def decrypt_ct_prime(ct_prime, decryption_report, filename):\n",
    "    start_decryption_time = perf_counter()\n",
    "    \n",
    "    R1, encrypted_data, R2 = ct_prime.split('||')\n",
    "    json_data = encrypted_data[len(\"Encrypted(\"):-1]\n",
    "    decrypted_data = json.loads(json_data)\n",
    "\n",
    "    end_decryption_time = perf_counter()\n",
    "    decryption_duration = end_decryption_time - start_decryption_time\n",
    "\n",
    "    decryption_report.append({\n",
    "        'filename': filename,\n",
    "        'decryption_duration': decryption_duration\n",
    "    })\n",
    "\n",
    "    return decrypted_data\n",
    "\n",
    "def save_merged_data(merged_data, user_id, folder_path, merge_report):\n",
    "    for i, batch in enumerate(merged_data):\n",
    "        start_merge_time = perf_counter()\n",
    "        merged_filename = f\"user_{user_id}_merged_{i+1}.txt\"\n",
    "        merged_file_path = os.path.join(folder_path, merged_filename)\n",
    "\n",
    "        with open(merged_file_path, 'w') as merged_file:\n",
    "            json.dump(batch, merged_file, indent=4)\n",
    "\n",
    "        end_merge_time = perf_counter()\n",
    "        merge_duration = end_merge_time - start_merge_time\n",
    "        merged_file_size = os.path.getsize(merged_file_path)\n",
    "\n",
    "        individual_files = [data['filename'] for data in batch]\n",
    "        individual_sizes = [data['file_size'] for data in batch]\n",
    "\n",
    "        merge_report.append({\n",
    "            'user_id': user_id,\n",
    "            'merged_file': merged_filename,\n",
    "            'merge_duration': merge_duration,\n",
    "            'merged_file_size': merged_file_size,\n",
    "            'individual_files': individual_files,\n",
    "            'individual_sizes': individual_sizes\n",
    "        })\n",
    "\n",
    "def read_and_decrypt_files(folder_path_base64, folder_path_merged, merge_report, decryption_report):\n",
    "    if not os.path.exists(folder_path_merged):\n",
    "        os.makedirs(folder_path_merged)\n",
    "\n",
    "    user_data = {}\n",
    "\n",
    "    for filename in os.listdir(folder_path_base64):\n",
    "        if filename.endswith('_base64.txt'):\n",
    "            file_path = os.path.join(folder_path_base64, filename)\n",
    "            file_size = os.path.getsize(file_path)\n",
    "\n",
    "            with open(file_path, 'r') as file:\n",
    "                encoded_data = file.read()\n",
    "                padded_encoded_data = encoded_data + '==='\n",
    "                try:\n",
    "                    decoded_data = base64.b64decode(padded_encoded_data).decode('utf-8')\n",
    "                    decrypted_info = decrypt_ct_prime(decoded_data, decryption_report, filename)\n",
    "\n",
    "                    user_id = decrypted_info['user_id']\n",
    "                    timestamp = datetime.strptime(decrypted_info['timestamp'], \"%Y-%m-%d %H_%M_%S\")\n",
    "                    if user_id not in user_data:\n",
    "                        user_data[user_id] = []\n",
    "                    decrypted_info['filename'] = filename\n",
    "                    decrypted_info['file_size'] = file_size\n",
    "                    user_data[user_id].append((timestamp, decrypted_info))\n",
    "                except Exception as e:\n",
    "                    print(f\"Error decoding file {filename}: {e}\")\n",
    "\n",
    "    for user_id, data in user_data.items():\n",
    "        data.sort(key=lambda x: x[0])  # Sort by timestamp\n",
    "        merged_data = []\n",
    "        current_batch = []\n",
    "        current_batch_time = None\n",
    "\n",
    "        for timestamp, info in data:\n",
    "            if current_batch_time is None or timestamp - current_batch_time <= timedelta(minutes=20):\n",
    "                current_batch.append(info)\n",
    "            else:\n",
    "                merged_data.append(current_batch)\n",
    "                current_batch = [info]\n",
    "            current_batch_time = timestamp\n",
    "\n",
    "        if current_batch:\n",
    "            merged_data.append(current_batch)\n",
    "\n",
    "        save_merged_data(merged_data, user_id, folder_path_merged, merge_report)\n",
    "\n",
    "def write_merge_report(merge_report, report_path):\n",
    "    merge_report_path = os.path.join(report_path, \"merge_report.csv\")\n",
    "    with open(merge_report_path, mode='w', newline='') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=['user_id', 'merged_file', 'merge_duration', 'merged_file_size', 'individual_files', 'individual_sizes'])\n",
    "        writer.writeheader()\n",
    "        for entry in merge_report:\n",
    "            writer.writerow(entry)\n",
    "\n",
    "def write_decryption_report(decryption_report, report_path):\n",
    "    decryption_report_path = os.path.join(report_path, \"decryption_report.csv\")\n",
    "    with open(decryption_report_path, mode='w', newline='') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=['filename', 'decryption_duration'])\n",
    "        writer.writeheader()\n",
    "        for entry in decryption_report:\n",
    "            writer.writerow(entry)\n",
    "\n",
    "def main():\n",
    "    folder_path_base64 = input(\"Enter the folder path containing Base64 encoded files for decryption: \")\n",
    "    folder_path_merged = input(\"Enter the folder path to save merged data: \")\n",
    "    report_path = input(\"Enter the directory for the reports: \")\n",
    "\n",
    "    merge_report = []\n",
    "    decryption_report = []\n",
    "    read_and_decrypt_files(folder_path_base64, folder_path_merged, merge_report, decryption_report)\n",
    "    write_merge_report(merge_report, report_path)\n",
    "    write_decryption_report(decryption_report, report_path)\n",
    "\n",
    "    print(f\"Merged files saved in {folder_path_merged}\")\n",
    "    print(f\"Reports saved in {report_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe93721",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24aefc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "C:/Users/ROHAN/IotSimulation/Base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057f7a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "C:/Users/ROHAN/IotSimulation/DecForAggreator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e787b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4704d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d673135e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec3c0f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff006a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the folder path containing Base64 encoded files for decryption: C:/Users/ROHAN/IotSimulation/Base64\n",
      "Enter the folder path to save merged data: C:/Users/ROHAN/IotSimulation/DecForAggreator\n",
      "Enter the directory for the reports: C:/Users/ROHAN/IotSimulation\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import base64\n",
    "import json\n",
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "from time import perf_counter\n",
    "\n",
    "def decrypt_ct_prime(ct_prime, decryption_report, filename):\n",
    "    start_decryption_time = perf_counter()\n",
    "    \n",
    "    R1, encrypted_data, R2 = ct_prime.split('||')\n",
    "    json_data = encrypted_data[len(\"Encrypted(\"):-1]\n",
    "    decrypted_data = json.loads(json_data)\n",
    "\n",
    "    end_decryption_time = perf_counter()\n",
    "    decryption_duration = end_decryption_time - start_decryption_time\n",
    "\n",
    "    decryption_report.append({\n",
    "        'filename': filename,\n",
    "        'decryption_duration': decryption_duration\n",
    "    })\n",
    "\n",
    "    return decrypted_data\n",
    "\n",
    "def save_merged_data(merged_data, user_id, folder_path, merge_report):\n",
    "    for i, batch in enumerate(merged_data):\n",
    "        start_merge_time = perf_counter()\n",
    "\n",
    "        # Extract authorized_data_users from the batch, assuming it's the same for all entries in the batch\n",
    "        authorized_users = batch[0]['authorized_data_users']\n",
    "        authorized_users_str = '_'.join(authorized_users)\n",
    "        \n",
    "        merged_filename = f\"user_{user_id}_auth_{authorized_users_str}_merged_{i+1}.txt\"\n",
    "        merged_file_path = os.path.join(folder_path, merged_filename)\n",
    "\n",
    "        with open(merged_file_path, 'w') as merged_file:\n",
    "            json.dump(batch, merged_file, indent=4)\n",
    "\n",
    "        end_merge_time = perf_counter()\n",
    "        merge_duration = end_merge_time - start_merge_time\n",
    "        merged_file_size = os.path.getsize(merged_file_path)\n",
    "\n",
    "        individual_files = [data['filename'] for data in batch]\n",
    "        individual_sizes = [data['file_size'] for data in batch]\n",
    "\n",
    "        merge_report.append({\n",
    "            'user_id': user_id,\n",
    "            'merged_file': merged_filename,\n",
    "            'merge_duration': merge_duration,\n",
    "            'merged_file_size': merged_file_size,\n",
    "            'individual_files': individual_files,\n",
    "            'individual_sizes': individual_sizes\n",
    "        })\n",
    "\n",
    "def read_and_decrypt_files(folder_path_base64, folder_path_merged, merge_report, decryption_report):\n",
    "    if not os.path.exists(folder_path_merged):\n",
    "        os.makedirs(folder_path_merged)\n",
    "\n",
    "    user_data = {}\n",
    "\n",
    "    for filename in os.listdir(folder_path_base64):\n",
    "        if filename.endswith('_base64.txt'):\n",
    "            file_path = os.path.join(folder_path_base64, filename)\n",
    "            file_size = os.path.getsize(file_path)\n",
    "\n",
    "            with open(file_path, 'r') as file:\n",
    "                encoded_data = file.read()\n",
    "                padded_encoded_data = encoded_data + '==='\n",
    "                try:\n",
    "                    decoded_data = base64.b64decode(padded_encoded_data).decode('utf-8')\n",
    "                    decrypted_info = decrypt_ct_prime(decoded_data, decryption_report, filename)\n",
    "\n",
    "                    user_id = decrypted_info['user_id']\n",
    "                    timestamp = datetime.strptime(decrypted_info['timestamp'], \"%Y-%m-%d %H_%M_%S\")\n",
    "                    if user_id not in user_data:\n",
    "                        user_data[user_id] = []\n",
    "                    decrypted_info['filename'] = filename\n",
    "                    decrypted_info['file_size'] = file_size\n",
    "                    user_data[user_id].append((timestamp, decrypted_info))\n",
    "                except Exception as e:\n",
    "                    print(f\"Error decoding file {filename}: {e}\")\n",
    "\n",
    "    for user_id, data in user_data.items():\n",
    "        data.sort(key=lambda x: x[0])  # Sort by timestamp\n",
    "        merged_data = []\n",
    "        current_batch = []\n",
    "        current_batch_time = None\n",
    "\n",
    "        for timestamp, info in data:\n",
    "            if current_batch_time is None or timestamp - current_batch_time <= timedelta(minutes=20):\n",
    "                current_batch.append(info)\n",
    "            else:\n",
    "                merged_data.append(current_batch)\n",
    "                current_batch = [info]\n",
    "            current_batch_time = timestamp\n",
    "\n",
    "        if current_batch:\n",
    "            merged_data.append(current_batch)\n",
    "\n",
    "        save_merged_data(merged_data, user_id, folder_path_merged, merge_report)\n",
    "\n",
    "def write_merge_report(merge_report, report_path):\n",
    "    merge_report_path = os.path.join(report_path, \"merge_report.csv\")\n",
    "    with open(merge_report_path, mode='w', newline='') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=['user_id', 'merged_file', 'merge_duration', 'merged_file_size', 'individual_files', 'individual_sizes'])\n",
    "        writer.writeheader()\n",
    "        for entry in merge_report:\n",
    "            writer.writerow(entry)\n",
    "\n",
    "def write_decryption_report(decryption_report, report_path):\n",
    "    decryption_report_path = os.path.join(report_path, \"decryption_report.csv\")\n",
    "    with open(decryption_report_path, mode='w', newline='') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=['filename', 'decryption_duration'])\n",
    "        writer.writeheader()\n",
    "        for entry in decryption_report:\n",
    "            writer.writerow(entry)\n",
    "\n",
    "def main():\n",
    "    folder_path_base64 = input(\"Enter the folder path containing Base64 encoded files for decryption: \")\n",
    "    folder_path_merged = input(\"Enter the folder path to save merged data: \")\n",
    "    report_path = input(\"Enter the directory for the reports: \")\n",
    "\n",
    "    merge_report = []\n",
    "    decryption_report = []\n",
    "    read_and_decrypt_files(folder_path_base64, folder_path_merged, merge_report, decryption_report)\n",
    "    write_merge_report(merge_report, report_path)\n",
    "    write_decryption_report(decryption_report, report_path)\n",
    "\n",
    "    print(f\"Merged files saved in {folder_path_merged}\")\n",
    "    print(f\"Reports saved in {report_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae77e524",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04aa27f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef310af7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841e82d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f331112a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11921f13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bf7d8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
